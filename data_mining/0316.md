### 퀴즈봄

10분 지각해서 놓침. 그냥 수업 나가버리고 싶은 마음을 겨우 참고 듣는 중. 아......... 망할....

#### Refinements : Combiner

* pre-aggregate the values in the mapper
    * (k, list(v1)) -> (k, v2)
* works only if the reduce function is
    * commutative
    * associative
    * ex. NOT to use : average, square-sum

#### Refinements : Partition Function

* key -> reduce task id
* hash(key) mod R
    * kind of random hash function
    * provides uniform distribution
* skewness가 있어서 random distribution 해도 한 쪽으로 쏠릴 수도
    * power-law에 따라서 좀 똑똑하게 분배하는 것도 하나의 방안

#### Problems Sutied For Map-Reduce

* host size
    * a large web corpus : (URL, size, date, ...)
    * find the total number of bytes
* language model
    * count the number of every 5-word sequence
    * map : extract (seq, cnt) from doc
    * reduce : combine the cnt
* distributed grep
    * map : emit a line if it matches a pattern
    * no reducer
    * a.k.a. map-only task
    * in this case, the mapper stores the result directly to DFS
* reverse web-link graph
    * map : output <target, source>
    * reduce : output <target, list(source)
* term-vector per host
    * map : output <hostname, term vector> using TF.IDF or else
    * reduce : 같은 호스트에 있는 정보들 모아서 짜른 다음 output <host,name, termvector>
* inverted index
    * map : output <word, doc.ID>
    * reduce : output <word, list(doc.ID)>
* (natural) join by map-reduce
    * R(a,b) x S(b,c)
    * map : (b, (a, R)), (b, (c, S))
    * reduce : pokapoka

#### cost measures for algorithms

* we have multiple machines
    * we should specify the number of machines in O notation
* typical way
    * communication cost
        * to mapper, to reducer, to DFS
    * elapsed communication cost
        * critical path of communication cost
    * (elapsed) computation cost
