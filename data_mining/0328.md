### Locality Sensitive Hashing

focus on pairs of sig.s likely to be from similar docs.

* Goal : Find docs with Jaccard sim. at least threshold s, say 0.8
* LSH : f(x, y) -> bool (whether x, y is a cand. pair)
* idea
    * M(i, x) = M(i, y) for at least frac. s values of i
    * problem : O(n^2)
* hash col.s of sig. mat. M to many bucket -> bucket[x] == bucket[y]
* hash several times!
* solution
    * divide each column into b bands (not overlapping)
    * let r = l / b, the number of rows per band
    * hash each band
    * cand. pairs are those that hash to the same bucket for >=1 bucket
    * tune b (or r) to optimize the result

#### hashing band

* simplifying assumption
    * same bucket == identical in that band
* example
    * M : 100 x 100000
    * b = 20, r = 5
    * s = 0.8
    * if sim(C1, C2) = 0.8, it should be a cand. pair
        * P(identical in one particular band) = 0.8 ^ 5 = 0.328
            * 근사적인 값인듯
        * P(C1 C2 not identical in all 20 bands) = (1-0.328)^20 = 0.00035
            * false negative
            * 더더욱 근사치인듯
    * if sim(C1, C2) = 0.3, it should not be a cand. pair
        * P(identical in one band) = 0.3^5 = 0.00243
        * false positive = (1-0.00243)^20 = 0.0474
* understanding terminologies
    * true positive. true negative
        * 이 명제는 사실이다
        * positive라고 예측했는데 사실이다
    * false positive : positive라고 예측했는데 사실 negative다
    * false negative : negative라고 말했는데 사실 positive다

#### LSH tradeoff

* pick the number of min-hashes and b (and r) to balance false pos/neg
* let the sim(C1, C2) = t
* y := P(at least one band identical) = 1 - (1 - t^r)^b
* if t = (1/b)^1/r then y ~= 1 - 1/e ~= 0.5
* 대충 이걸 S모양 커브의 중간점으로 잡고
* 상황에 따라 (1/b)^(1/r)이 s보다 작도록/크도록 조절하세요


#### LSH summary

1. M, b, r을 잘 튜닝해라
2. cand. pair 구해서 실제로 similar sig.인지 봐라
3. optional : 실제로 similar doc.인지 봐라

# Mining data streams

* Data Streams
    * 보통 전체 데이터셋을 미리 알 수 없다
    * stream management는 특히 input rate가 외적 요소에 의해 결정될 때 중요
    * data를 infinite & non-stationary하다고 가정
        * distribution changes over time

* The Stream model
    * the situation
        * input elements, which is tuples
        * enter at rapid rate
        * at one or more input ports
    * The system cannot store the entire stream __accessibly__
        * data do not fit in memory
        * disks are slow
    * general stream processing model
        * input/output
        * processor
        * query
            * standing queries
            * ad-hoc queries
        * storage
            * limited working storage
            * archival storage
* problems
    * sampling data from a stream
    * queries over sliding windows
    * filtering a data stream
    * counting distinct elem
    * estimating moments
    * finding frequent elem
* application
    * mining query streams : google news
    * mining click streams : naver 실검
    * mining social network news feeds : twitter, facebook

#### sampling from a data stream

1. fixed proportion
1. random sample of fixed size

##### fixed proportion

* search engine : (user, query, time)
* "how often did a user run the same query in a single day?"
* have space to store 1/10 of query stream
* naive solution : if randint(0, 9) == 0
