#### 보고서

영어로 쓰세용

Map-Reduce 프레임워크는 아래의 기능을 제공한다

* partitioning input data
* scheduling program.s execution
* group by key
* handle machine failure
* inter-machine communication

input이랑 output은 DFS에 저장되어 있다

* 서로 다른 machine에 replicate도 넣어야 함
* intermediate, grouped data 등은 temporary하므로 local file system에 저장

Q. sorting 어떻게?

1. 일단 map 다 하고
    * ex. (a, 1), (b, 1), (c, 1), (b, 1)
2. R files를 만듬 (각 reducer에 갈 것들)
    * 각 파일은 sorted
    * ex. R1 : [(a, 1), (c, 1)], R2 : [(b, 1), (b, 1)]
3. reducer에서 merge

Q. mapper, reducer 서로 다른 machine이어야 하는가?

* ㄴㄴ
* a single machine이 map도 하고 reduce도 함
* 하던 작업 완전히 끝낸 뒤에 다음 작업 시작함


partitioning function(hash function)

scheduler는 distributed file system에 저장된 data를 최대한 움직이지 않도록 scheduling함. (map function을 해당 machine에서 부른다)


coordination : master

* 640 MB file -> 10 chunk
    * initially in idle state
* 5 machines
* idle tasks는 각 machine에 scheduling됨
    * sequential하게 읽어서 mapper에 보냄
    * C6을 M1에 보내려 하는데 M1에 없으면? 
    * 데이터 복사해서 전송ㅠ
    * 근데 그런 경우 잘 없음
* 끝나면 master notde에 R intermediate file의 정보를 전송
* ping 보낸데

failures
* map worker failure
    * 거기서 처리 중인/처리한 map task를 idle로 처리
* reduce worker failure
    * 처리 중인 것들만 idle로 (왜???)
* master node failure
    * aborted

map & reduce job 갯수?

* M >> n
    * fault recovery 시간 짧아짐
    * pipeline shuffling
    * better dynamic load balancing
    * slide 30 참조
        * reduce 같은 곳에서 하면 read 안해도 되지 않냐
        * 걍 예시임. 보통 doesnt matter
* M > R

refinements : backup tasks

* map이 다 끝나야 reduce가 됨
* 하나가 엄청 오래 걸리면? (skewed)
    * job의 종류가 다르기 때문에
    * 기계가 느려서
    * bad disk
    * 등등
* 해결책 : backup tasks
    * Q. backup 어떻게 정해요
        * 아무거나 실행하기도 하고
        * progress 보고 예측된 완료 시간이 긴 거 선택할 수도 있다

